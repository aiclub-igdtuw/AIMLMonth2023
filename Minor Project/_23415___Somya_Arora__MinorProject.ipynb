{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MINOR PROJECT**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3j27_cT6kBA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 1** - Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "0cMtLrokuof_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the distribution of ESRB ratings in the dataset? How many games fall into each rating category (E, ET, T, M)? Can you create a bar plot to visualize the distribution?"
      ],
      "metadata": {
        "id": "Ec0_MjBDkkJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a website link to a dataset\n",
        "dataset_url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "data = pd.read_csv(dataset_url)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Assuming the dataset has a column called 'esrb_rating' representing the game ratings\n",
        "\n",
        "# Filter the dataset by rating categories\n",
        "e_games = data[data['esrb_rating'] == 'E']\n",
        "et_games = data[data['esrb_rating'] == 'ET']\n",
        "t_games = data[data['esrb_rating'] == 'T']\n",
        "m_games = data[data['esrb_rating'] == 'M']\n",
        "\n",
        "# Count the number of games in each rating category\n",
        "e_count = len(e_games)\n",
        "et_count = len(et_games)\n",
        "t_count = len(t_games)\n",
        "m_count = len(m_games)\n",
        "\n",
        "# Create a bar plot\n",
        "categories = ['E', 'ET', 'T', 'M']\n",
        "counts = [e_count, et_count, t_count, m_count]\n",
        "\n",
        "plt.bar(categories, counts)\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Rating Category')\n",
        "plt.ylabel('Number of Games')\n",
        "plt.title('Distribution of Game Ratings')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0tywXRCfgDr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing your analysis and observation"
      ],
      "metadata": {
        "id": "DQhXQwp9p263"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vo4e7f6PvhVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Jlm2VnhvhST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Are there any specific ESRB content features that are more prevalent in certain rating categories? Can you analyze the frequency of each content feature for different ESRB ratings and determine if there are any significant differences?\n"
      ],
      "metadata": {
        "id": "cPa96surrJOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# we  have a imported website link to a dataset\n",
        "dataset_url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "data = pd.read_csv(dataset_url)"
      ],
      "metadata": {
        "id": "xB_9DeBJp2LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we  have already loaded the dataset into a DataFrame named 'data'\n",
        "\n",
        "# Select the relevant columns for analysis\n",
        "selected_columns = ['esrb_rating', 'alcohol_reference', 'blood', 'blood_and_gore', 'cartoon_violence',\n",
        "                    'crude_humor', 'drug_reference', 'fantasy_violence', 'intense_violence',\n",
        "                    'language', 'lyrics', 'mature_humor', 'mild_blood', 'mild_cartoon_violence',\n",
        "                    'mild_fantasy_violence', 'mild_language', 'mild_lyrics', 'mild_suggestive_themes',\n",
        "                    'mild_violence', 'no_descriptors', 'nudity', 'partial_nudity',\n",
        "                    'sexual_content', 'sexual_themes', 'simulated_gambling',\n",
        "                    'strong_janguage', 'strong_sexual_content', 'suggestive_themes',\n",
        "                    'use_of_alcohol', 'use_of_drugs_and_alcohol', 'violence']\n",
        "\n",
        "# Subset the data with the selected columns\n",
        "subset_data = data[selected_columns]\n",
        "\n",
        "# Group the data by ESRB rating and calculate the frequency of each content feature\n",
        "rating_counts = subset_data.groupby('esrb_rating').sum()\n",
        "\n",
        "# Calculate the total number of games in each rating category\n",
        "total_games = data['esrb_rating'].value_counts()\n",
        "\n",
        "# Calculate the frequency of each content feature for each rating category\n",
        "frequency = rating_counts.divide(total_games, axis=0)\n",
        "\n",
        "# Display the frequency of each content feature for different ESRB ratings\n",
        "print(frequency)"
      ],
      "metadata": {
        "id": "4BB9XdGqp2Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing your analysis and observations"
      ],
      "metadata": {
        "id": "EfjH6OQvv-8K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HktaYYj1wHeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTLBZ96Qwgsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there a correlation between the presence of certain content features (e.g., violence, sexual content) and the assigned ESRB rating? Can you analyze the correlation between these variables and determine if certain features are strong indicators of a specific rating category?"
      ],
      "metadata": {
        "id": "UmtxT6Y9wbSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Import the dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Prepare the data\n",
        "features = ['violence', 'sexual_content']  # Adjust this list based on your dataset's columns\n",
        "df = data[['esrb_rating'] + features]\n",
        "df['esrb_rating'] = df['esrb_rating'].astype('category')\n",
        "\n",
        "# Perform correlation analysis\n",
        "for feature in features:\n",
        "    crosstab = pd.crosstab(df[feature], df['esrb_rating'])\n",
        "    chi2, p_value, _, _ = chi2_contingency(crosstab)\n",
        "    print(f'Chi-square test for {feature}: p-value = {p_value}')\n",
        "\n",
        "# Visualize the correlations\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NnLrdGcRwbSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing your analysis and observation"
      ],
      "metadata": {
        "id": "0aFNKRQSwbSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AyPGfHNwbSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymmJAoJJwbSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you identify any patterns in the relationship between ESRB ratings and the presence of multiple content features? For example, are there certain combinations of features that are more common in specific rating categories?"
      ],
      "metadata": {
        "id": "VjYUkQCLwbSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import the dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select the relevant columns for analysis\n",
        "selected_columns = ['esrb_rating', 'violence', 'sexual_content', 'language', 'drug_reference']\n",
        "\n",
        "# Subset the data with the selected columns\n",
        "subset_data = data[selected_columns]\n",
        "\n",
        "# Create a binary indicator variable for the presence of each content feature\n",
        "binary_data = subset_data.copy()\n",
        "binary_data.iloc[:, 1:] = binary_data.iloc[:, 1:].apply(lambda x: x > 0)\n",
        "\n",
        "# Extract unique rating categories\n",
        "rating_categories = binary_data['esrb_rating'].unique()\n",
        "\n",
        "# Create an empty frequency table\n",
        "frequency_table = pd.DataFrame(columns=binary_data.columns[1:], index=rating_categories)\n",
        "frequency_table = frequency_table.fillna(0)\n",
        "\n",
        "# Calculate the frequency of content feature combinations for each ESRB rating\n",
        "for index, row in binary_data.iterrows():\n",
        "    rating = row['esrb_rating']\n",
        "    features = row[1:]\n",
        "    frequency_table.loc[rating] = frequency_table.loc[rating].add(features, fill_value=0)\n",
        "\n",
        "# Display the frequency table\n",
        "print(frequency_table)\n"
      ],
      "metadata": {
        "id": "CrTTrNYhwbSa",
        "outputId": "30dc753a-ae3a-4e9b-edf3-071070496748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    violence  sexual_content  language  drug_reference\n",
            "E          0               0         0               0\n",
            "ET         4               0        31              12\n",
            "M         21              38        63              27\n",
            "T         96              27       111              27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add more cells if required"
      ],
      "metadata": {
        "id": "8PgE1Q1JwbSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing your analysis and observations"
      ],
      "metadata": {
        "id": "gr4VOY0gwbSa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ff6vpUywHbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well can the ESRB rating be predicted based on the presence of different content features? Can you build a classification model to predict the ESRB rating using the available features and evaluate its performance using appropriate metrics?"
      ],
      "metadata": {
        "id": "VbWuvMbqwdgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Import the dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select the relevant columns for analysis\n",
        "selected_columns = ['esrb_rating', 'violence', 'sexual_content', 'language', 'drug_reference']\n",
        "\n",
        "# Subset the data with the selected columns\n",
        "subset_data = data[selected_columns]\n",
        "\n",
        "# Create a binary indicator variable for the presence of each content feature\n",
        "binary_data = subset_data.copy()\n",
        "binary_data.iloc[:, 1:] = binary_data.iloc[:, 1:].apply(lambda x: x > 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = binary_data.iloc[:, 1:]\n",
        "y = binary_data['esrb_rating']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the model performance metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{classification_report}\")\n"
      ],
      "metadata": {
        "id": "f8V6THB7wdgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing your analysis and observation"
      ],
      "metadata": {
        "id": "m8JUp2kAwdgh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNy3P4C2wdgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kfkABpl6wdgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 2** - Classification/Regression"
      ],
      "metadata": {
        "id": "Ox8z7yNIwosG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform following steps on the same dataset which you used for EDA.\n",
        "> - Data Preprocessing (as per requirement)\n",
        "> - Feature Engineering\n",
        "> - Split dataset in train-test (80:20 ratio)\n",
        "> - Model selection\n",
        "> - Model training\n",
        "> - Model evaluation\n",
        "> - Fine-tune the Model\n",
        "> - Make predictions\n",
        "\n",
        "Summarize your model's performance by evaluation metrices\n",
        "\n"
      ],
      "metadata": {
        "id": "glXi_qALwz7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Import the dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/arora-somya/dataset/main/Video_games_esrb_rating.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Data Preprocessing (if needed)\n",
        "# Assuming no preprocessing is required in this example\n",
        "\n",
        "# Feature Engineering (if needed)\n",
        "# Assuming no feature engineering is required in this example\n",
        "\n",
        "# Select the relevant columns for analysis\n",
        "selected_columns = ['esrb_rating', 'violence', 'sexual_content', 'language', 'drug_reference']\n",
        "\n",
        "# Subset the data with the selected columns\n",
        "subset_data = data[selected_columns]\n",
        "\n",
        "# Create a binary indicator variable for the presence of each content feature\n",
        "binary_data = subset_data.copy()\n",
        "binary_data.iloc[:, 1:] = binary_data.iloc[:, 1:].apply(lambda x: x > 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = binary_data.iloc[:, 1:]\n",
        "y = binary_data['esrb_rating']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model selection\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Model training\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Model evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the model performance metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{classification_report_result}\")\n",
        "\n",
        "# Fine-tune the Model\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions using the fine-tuned model\n",
        "best_clf = grid_search.best_estimator_\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Model evaluation with fine-tuned model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_result = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the model performance metrics with fine-tuned model\n",
        "print(f\"Accuracy (Fine-tuned Model): {accuracy}\")\n",
        "print(f\"Classification Report (Fine-tuned Model):\\n{classification_report_result}\")\n"
      ],
      "metadata": {
        "id": "J2t6q9hwxCIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}