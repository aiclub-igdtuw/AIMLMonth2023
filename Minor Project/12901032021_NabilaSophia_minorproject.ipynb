{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b4acf3",
   "metadata": {},
   "source": [
    "Q1. Are there any inconsistent or incorrect data entries that need to be corrected or standardized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e28152",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['budget', 'revenue', 'runtime', 'vote_count', 'vote_average']\n",
    "for column in numeric_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    incorrect_values = df[df[column].isnull()]\n",
    "    print(f\"Incorrect values in {column}:\")\n",
    "    print(incorrect_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['original_language', 'status']\n",
    "for column in categorical_columns:\n",
    "    incorrect_values = df[df[column].isnull() | (df[column] == '')]\n",
    "    print(f\"Incorrect values in {column}:\")\n",
    "    print(incorrect_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff548b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with missing or empty values\n",
    "invalid_rows = df[df.isnull().any(axis=1)]\n",
    "print(\"Rows with missing or empty values:\")\n",
    "print(invalid_rows)\n",
    "\n",
    "# Identify rows with duplicate entries\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(\"Duplicate rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904af8e0",
   "metadata": {},
   "source": [
    "These steps will help identify any missing values, incorrect values in specific columns, and inconsistencies across the entire dataset. We can further apply appropriate data cleaning or standardization techniques based on the specific issues you identify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a2fe2",
   "metadata": {},
   "source": [
    "Q2. How can we visualize the distribution of movie revenue and runtime in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Plotting the distribution of movie revenue\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['revenue'], bins=50, color='skyblue')\n",
    "plt.title('Distribution of Movie Revenue')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the distribution of movie runtime\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['runtime'].dropna(), bins=50, color='lightgreen')\n",
    "plt.title('Distribution of Movie Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b52a17",
   "metadata": {},
   "source": [
    "In this code, we first load the dataset using pd.read_csv() and assign it to the DataFrame df. Then we use plt.hist() to create histograms for both the 'revenue' and 'runtime' columns. The bins parameter determines the number of bins or bars in the histogram. Finally, we use plt.title(), plt.xlabel(), and plt.ylabel() to set the plot title, x-label, and y-label, respectively. Calling plt.show() displays the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abf064",
   "metadata": {},
   "source": [
    "Q3. Can we create visualizations to understand the relationship between variables (popularity, budget) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Create a scatter plot to visualize the relationship between popularity and budget\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['popularity'], df['budget'], color='orange', alpha=0.6)\n",
    "plt.title('Relationship between Popularity and Budget')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8be5a1",
   "metadata": {},
   "source": [
    "In this code, we first load the dataset using pd.read_csv() and assign it to the DataFrame df. Then we use plt.scatter() to create a scatter plot with 'popularity' on the x-axis and 'budget' on the y-axis. The color parameter sets the color of the data points, and alpha determines the transparency of the points. We also set the plot title, x-label, and y-label using plt.title(), plt.xlabel(), and plt.ylabel() respectively. Finally, calling plt.show() displays the scatter plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941245c",
   "metadata": {},
   "source": [
    "Q4. How can we visualize the correlation between features vote average and vote count ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Create a scatter plot to visualize the correlation between vote_average and vote_count\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['vote_average'], df['vote_count'], color='purple', alpha=0.6)\n",
    "plt.title('Correlation between Vote Average and Vote Count')\n",
    "plt.xlabel('Vote Average')\n",
    "plt.ylabel('Vote Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3f6f2",
   "metadata": {},
   "source": [
    "In this code, we first load the dataset using pd.read_csv() and assign it to the DataFrame df. Then we use plt.scatter() to create a scatter plot with 'vote_average' on the x-axis and 'vote_count' on the y-axis. The color parameter sets the color of the data points, and alpha determines the transparency of the points. We also set the plot title, x-label, and y-label using plt.title(), plt.xlabel(), and plt.ylabel() respectively. Finally, calling plt.show() displays the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bbc372",
   "metadata": {},
   "source": [
    "Q5. What are the key insights you can derive from the dataset in terms of its structure, size, and basic statistics? Create a summary report . ( hint: use pandas .describe() function ) , Also share your insights you learned by this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Summary report using describe()\n",
    "summary_report = df.describe(include='all')\n",
    "\n",
    "# Print the summary report\n",
    "print(summary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe99af",
   "metadata": {},
   "source": [
    "In this code, we load the dataset using pd.read_csv() and assign it to the DataFrame df. Then we use the describe() function on the DataFrame to generate the summary report. The include='all' parameter ensures that the report includes statistics for all columns, including categorical variables. The summary report will provide basic statistics such as count, mean, standard deviation, minimum, quartiles, and maximum for each numerical column, as well as the unique count and most frequent value for categorical columns.\n",
    "\n",
    "By analyzing the summary report, you can derive several key insights about the dataset:\n",
    "\n",
    "Structure: The report shows the structure of the dataset, including the number of rows and columns, the data types of each column, and basic statistics for both numerical and categorical variables. Size: You can determine the size of the dataset based on the number of rows and columns mentioned in the report. Basic statistics: The summary report provides key statistical measures such as count, mean, standard deviation, minimum, quartiles, and maximum for numerical columns. These statistics help in understanding the central tendencies, variations, and range of the data. Missing values: The count statistic in the summary report can reveal if there are any missing values in the dataset. Columns with missing values will have a count lower than the total number of rows. Distribution: The summary report gives an overview of the distribution of numerical variables by providing quartiles, which can help identify outliers or skewed distributions. Categorical variables: For categorical columns, the summary report provides the unique count and the most frequent value, which can give insights into the variety and dominant categories present in the dataset. By examining the summary report, you can gain a better understanding of the dataset's structure, size, and basic statistics, which can guide further analysis and decision-making in your data exploration process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06cc2f",
   "metadata": {},
   "source": [
    "TASK 2 - Classification/Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acecfac4",
   "metadata": {},
   "source": [
    "To determine whether the problem requires classification or regression analysis, you need to consider the nature of the target variable or the problem you want to solve. In the case of the \"tmdb_5000_movies.csv\" dataset, the problem you want to solve will dictate whether classification or regression techniques are appropriate.\n",
    "\n",
    "Here are a few steps to help you determine the appropriate analysis technique:\n",
    "\n",
    "Identify the target variable: In this dataset, the target variable should be the variable you want to predict or analyze. Take a look at the available columns and decide which variable is the focus of your analysis. Determine the type of the target variable: If the target variable is categorical or discrete and represents different classes or categories, such as genre or movie status (e.g., released, in production), then the problem requires classification analysis. If the target variable is continuous and represents a quantity that can take any value within a range, such as movie revenue or popularity, then the problem requires regression analysis. Choose the appropriate analysis technique: For classification problems, you can use techniques such as logistic regression, decision trees, random forests, support vector machines (SVM), or naive Bayes classifiers. For regression problems, you can use techniques such as linear regression, decision trees, random forests, support vector regression (SVR), or gradient boosting regressors. Once you have determined the appropriate analysis technique, you can implement it using Python. Here's an example of how to perform classification or regression analysis using logistic regression and linear regression, respectively:\n",
    "\n",
    "Classification analysis example using logistic regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1794a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Define the features and target variable\n",
    "\n",
    "X = df[['feature1', 'feature2', ...]]  # Specify the relevant features\n",
    "y = df['target_variable']\n",
    "\n",
    "# Specify the target variable\n",
    "\n",
    "# Instantiate and fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176064b",
   "metadata": {},
   "source": [
    "Regression analysis example using linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Define the features and target variable\n",
    "\n",
    "X = df[['feature1', 'feature2', ...]]  # Specify the relevant features\n",
    "y = df['target_variable']  # Specify the target variable\n",
    "\n",
    "# Instantiate and fit the linear regression model\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "predictions = model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
